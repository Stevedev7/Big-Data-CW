{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=UserWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Building up a basic predictive model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and transformation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv(\"Manhattan12.csv\", skiprows=4)\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename incorrectly formatted column names (e.g. SALE\\nPRICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(\"\\n\", \"\").str.replace(\" \", \"_\")\n",
    "df.rename(columns={\"SALEPRICE\": \"SALE_PRICE\", \"APARTMENTNUMBER\": \"APARTMENT_NUMBER\"}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of categorical variables and another for the numerical variables\n",
    "### For each numerical column, remove the ',' the '$' for the sale price, and then convert them to numeric.\n",
    "### Convert the 'SALE DATE' to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.replace(\"\\n\", \"\")\n",
    "\n",
    "def format_and_convert_column_to_numeric(col, dtype):\n",
    "    df[col] = df[col].str.replace(\",\",\"\").str.replace(\"$\",\"\").astype(dtype)\n",
    "    \n",
    "format_and_convert_column_to_numeric('SALE_PRICE', np.int64)\n",
    "\n",
    "# Convert To datetime\n",
    "df['SALE_DATE'] =pd.to_datetime(df['SALE_DATE'], dayfirst=True)\n",
    "\n",
    "df['YEAR_BUILT'] = df['YEAR_BUILT'].astype(np.int64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of categorical variables and another for the numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.select_dtypes(include='object').columns.tolist()\n",
    "numerical = df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "print(\"Categorical columns: \", categorical)\n",
    "print(\"Numerical columns: \", numerical)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each categorical variable, remove the spaces, and then replace the empty string '' by NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical] = df[categorical].applymap(lambda x: x.replace(r\" +\", \"\"))\n",
    "df[categorical] = df[categorical].applymap(lambda x: \" \".join(x.split()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the zeros in Prices, Land squares, etc. by NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical] = df[categorical].replace(\"\", np.nan)\n",
    "df[numerical] = df[numerical].replace(0, np.nan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show a summary of all missing values as well as the summary statistics (Percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() / df.shape[0] * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the columns 'BOROUGH', 'EASE-MENT', 'APARTMENT NUMBER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['BOROUGH', 'EASE-MENT', 'APARTMENT_NUMBER'], inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicates if any\n",
    "### Drop rows with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and remove outliers if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "z_scores = np.abs(stats.zscore(df[numerical]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(z_scores<3).all(axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the shape of the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider the log of the prices and normalise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['SALE_PRICE'] = np.log(df['SALE_PRICE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical.remove(\"SALE_PRICE\")\n",
    "df[numerical] = (df[numerical] - df[numerical].min()) / (df[numerical].max() - df[numerical].min())\n",
    "numerical.append(\"SALE_PRICE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the prices across neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 12))\n",
    "sns.set_theme(font_scale=1.2)\n",
    "fig = sns.barplot(data=df ,y='SALE_PRICE', x='NEIGHBORHOOD', order=df.groupby(['NEIGHBORHOOD']).mean().sort_values('SALE_PRICE').index)\n",
    "plt.xticks(rotation=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df[numerical].corr().round(2), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Matrix Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='ticks', font_scale=1.2, palette='mako')\n",
    "sns.pairplot(data=df, hue='SALE_PRICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 10))\n",
    "fig = sns.boxplot(data=df, palette='pastel').set(title='Box plot')\n",
    "sns.set( font_scale=0.8)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10, rotation=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the predictors that would have impact in predicting house prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, [0, 1, 8, 10, 11, 12, 15, 3, 4, 7, 9, 13, 14, 16]]\n",
    "df.iloc[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0, 1, 2, 3, 4, 5, 6, 7, 8])], remainder='passthrough')\n",
    "X = ct.fit_transform(X.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values, test_size=0.2, random_state=69420)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'Mean Absolute Error - {mae}')\n",
    "print(f'Mean Squared Error - {mse}')\n",
    "print(f'Root Mean Squared Error - {rmse}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the y_true and y_pred values side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(np.concatenate((y_test.reshape(-1, 1), y_pred.reshape(-1, 1)), axis=1), columns=['Y_TRUE', 'Y_PRED'])\n",
    "predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_validate(LinearRegression(), X_test, y_test, cv=5, scoring=('r2', 'neg_root_mean_squared_error'))\n",
    "print(\"Cross Validation results\")\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.set_theme(style='whitegrid', font_scale=1, palette='Spectral')\n",
    "sns.histplot(y_test - y_pred, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Building up a basic predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv(\"Manhattan12.csv\", skiprows=4)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dtype conversion\n",
    "df.columns = df.columns.str.strip().str.replace(\"\\n\", \"\")\n",
    "    \n",
    "format_and_convert_column_to_numeric('SALEPRICE', np.int64)\n",
    "format_and_convert_column_to_numeric('GROSS SQUARE FEET', np.float64)\n",
    "format_and_convert_column_to_numeric('LAND SQUARE FEET', np.float64)\n",
    "format_and_convert_column_to_numeric('RESIDENTIAL UNITS', np.int64)\n",
    "format_and_convert_column_to_numeric('TOTAL UNITS', np.int64)\n",
    "\n",
    "# Convert To datetime\n",
    "df['SALE DATE'] =pd.to_datetime(df['SALE DATE'], dayfirst=True)\n",
    "\n",
    "df['YEAR BUILT'] = df['YEAR BUILT'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(\"\\n\", \"\").str.replace(\" \", \"_\")\n",
    "df.rename(columns={\"SALEPRICE\": \"SALE_PRICE\", \"APARTMENTNUMBER\": \"APARTMENT_NUMBER\"}, inplace=True)\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.select_dtypes(include='object').columns.tolist()\n",
    "numerical = df.select_dtypes(include=['int', 'float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical] = df[categorical].apply(lambda x: x.str.strip())\n",
    "df.replace(\"\", np.nan, inplace=True)\n",
    "df.replace(0, np.nan, inplace=True)\n",
    "df.isna().sum() / len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['year_built'], how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sale_year'] = pd.DatetimeIndex(df.sale_date).year\n",
    "df['sale_month'] = pd.DatetimeIndex(df.sale_date).month\n",
    "df['building_age'] = 2013 - df['year_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['borough', 'address', 'ease-ment', 'apartment_number', 'sale_date', 'year_built'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.select_dtypes(include='object').columns.tolist()\n",
    "numerical = df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "print(\"Categorical columns: \", categorical)\n",
    "print(\"Numerical columns: \", numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_values = df[numerical].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sale_price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['sale_price'] > 1000000) & (df['sale_price'] < 15000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=categorical, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['building_class_at_present', 'tax_class_at_present', 'tax_class_at_time_of_sale', 'building_class_at_time_of_sale', 'total_units'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.select_dtypes(include='object').columns.tolist()\n",
    "numerical = df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "print(\"Categorical columns: \", categorical)\n",
    "print(\"Numerical columns: \", numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(df[numerical].corr().round(2), annot=True, cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='sale_price')\n",
    "y = df['sale_price']\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigborhood_le = LabelEncoder()\n",
    "building_class_category_le = LabelEncoder()\n",
    "X['encoded_neighborhood'] = neigborhood_le.fit_transform(X['neighborhood'])\n",
    "X['encoded_building_class_category'] = building_class_category_le.fit_transform(X['building_class_category'])\n",
    "X.drop(columns=['building_class_category', 'neighborhood'], inplace=True)\n",
    "final_columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test, columns=final_columns)\n",
    "X_train = pd.DataFrame(X_train, columns=final_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LinearRegression()\n",
    "imputer = IterativeImputer(estimator=le, min_value=train.min())\n",
    "imputer.fit(train)\n",
    "train = pd.DataFrame(imputer.transform(train), columns=final_columns)\n",
    "test = pd.DataFrame(imputer.transform(test), columns=final_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['commercial_units', 'residential_units']] = train[['commercial_units', 'residential_units']].applymap(lambda x: round(x))\n",
    "test[['commercial_units', 'residential_units']] = test[['commercial_units', 'residential_units']].applymap(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['encoded_neighborhood', 'encoded_building_class_category']] = train[['encoded_neighborhood', 'encoded_building_class_category']].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 12))\n",
    "sns.set_theme(font_scale=1.2)\n",
    "fig = sns.barplot(data=train ,y='sale_price', x='encoded_neighborhood', order=train.groupby(['encoded_neighborhood']).mean().sort_values('sale_price').index)\n",
    "plt.xticks(rotation=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sale_price'] = np.log(train['sale_price'])\n",
    "test['sale_price'] = np.log(test['sale_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 12))\n",
    "sns.set_theme(font_scale=1.2)\n",
    "fig = sns.barplot(data=train ,y='sale_price', x='encoded_neighborhood', order=train.groupby(['encoded_neighborhood']).mean().sort_values('sale_price').index)\n",
    "plt.xticks(rotation=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigborhood_le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 12))\n",
    "sns.set_theme(font_scale=1.2)\n",
    "sns.heatmap(train[numerical].corr().round(2), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['encoded_neighborhood', 'encoded_building_class_category']] = train[['encoded_neighborhood', 'encoded_building_class_category']].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = train.quantile(0.25)\n",
    "Q3 = train.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "train = train[~((train < (Q1 - 1.5 * IQR)) |(train > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "'''\n",
    "Zolduoarrati, E. (2019, December 17). Remove Outliers in Pandas DataFrame using Percentiles. Stack Overflow. https://stackoverflow.com/questions/35827863/remove-outliers-in-pandas-dataframe-using-percentiles\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical.extend(['encoded_neighborhood', 'encoded_building_class_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "standard_scaler = StandardScaler()\n",
    "X_columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = standard_scaler.fit_transform(train.iloc[:, :-1])\n",
    "X_train_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train_sc, columns=X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sc = standard_scaler.transform(test.iloc[:, :-1])\n",
    "X_test = pd.DataFrame(X_test_sc, columns=X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=500, random_state=69420)\n",
    "    kmeans.fit(X_train.values)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "sns.lineplot(x=range(1, 11), y=wcss, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clusters = 2\n",
    "\n",
    "k_means_model = KMeans(n_clusters=number_of_clusters, random_state=69420, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clusters = k_means_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = k_means_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X_train['land_square_feet'], y=X_train['gross_square_feet'], hue=k_means_model.labels_, palette='hot')\n",
    "\n",
    "# add cluster centroids to the scatter plot\n",
    "sns.scatterplot(x=k_means_model.cluster_centers_[:, 5], y=k_means_model.cluster_centers_[:, 6], color='black', marker='X', s=100)\n",
    "\n",
    "plt.title('Clusters and Centroids')\n",
    "plt.xlabel('Land Square Feet')\n",
    "plt.ylabel('Gross Square Feet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a = train[train_clusters == 0].iloc[:, :-1]\n",
    "y_train_a = train[train_clusters == 0].iloc[:, -1]\n",
    "X_train_b = train[train_clusters == 1].iloc[:, :-1]\n",
    "y_train_b = train[train_clusters == 1].iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_a = LinearRegression()\n",
    "regressor_b = LinearRegression()\n",
    "\n",
    "regressor_a.fit(X_train_a, y_train_a)\n",
    "regressor_b.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.iloc[:, :-1]\n",
    "y_test = test.iloc[:, -1]\n",
    "test_clusters = k_means_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_a = X_test[test_clusters == 0].values\n",
    "y_test_a = y_test[test_clusters == 0].values\n",
    "X_test_b = X_test[test_clusters == 1].values\n",
    "y_test_b = y_test[test_clusters == 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a = regressor_a.predict(X_test_a)\n",
    "y_pred_b = regressor_b.predict(X_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_a_pred = pd.DataFrame(np.concatenate((y_test_a.reshape(-1, 1), y_pred_a.reshape(-1, 1)), axis=1), columns=['Y_TRUE', 'Y_PRED'])\n",
    "cluster_b_pred = pd.DataFrame(np.concatenate((y_test_b.reshape(-1, 1), y_pred_b.reshape(-1, 1)), axis=1), columns=['Y_TRUE', 'Y_PRED'])\n",
    "final_pred = pd.concat([cluster_a_pred, cluster_b_pred], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(final_pred.iloc[:, 0], final_pred.iloc[:, 1])\n",
    "mse = mean_squared_error(final_pred.iloc[:, 0], final_pred.iloc[:, 1])\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'Mean Absolute Error - {mae}')\n",
    "print(f'Mean Squared Error - {mse}')\n",
    "print(f'Root Mean Squared Error - {rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdcw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
